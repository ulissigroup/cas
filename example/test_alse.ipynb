{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2037ea1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/gpytorch/lazy/triangular_lazy_tensor.py:124: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\n",
      "X = torch.triangular_solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve_triangular(A, B). (Triggered internally at  ../aten/src/ATen/native/BatchLinearAlgebra.cpp:2189.)\n",
      "  res = torch.triangular_solve(right_tensor, self.evaluate(), upper=self.upper).solution\n",
      "/opt/conda/lib/python3.9/site-packages/gpytorch/utils/cholesky.py:44: NumericalWarning: A not p.d., added jitter of 1.0e-06 to the diagonal\n",
      "  warnings.warn(f\"A not p.d., added jitter of {jitter_new:.1e} to the diagonal\", NumericalWarning)\n",
      "/opt/conda/lib/python3.9/site-packages/gpytorch/utils/cholesky.py:44: NumericalWarning: A not p.d., added jitter of 1.0e-05 to the diagonal\n",
      "  warnings.warn(f\"A not p.d., added jitter of {jitter_new:.1e} to the diagonal\", NumericalWarning)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (512) must match the size of tensor b (10) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/jovyan/shared-scratch/leo/alse/example/test_alse.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://k8s-container%2Bcontext%3Dulissigroup-desktops%2Bpodname%3Dleo-0%2Bnamespace%3Dleo1839%2Bname%3Dleo%2Bimage%3Dulissigroup%252fkubeflow%253aarl/home/jovyan/shared-scratch/leo/alse/example/test_alse.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m algo \u001b[39m=\u001b[39m alse(X, bounds, [width, pow_cap, wth], constraints)\n\u001b[1;32m     <a href='vscode-notebook-cell://k8s-container%2Bcontext%3Dulissigroup-desktops%2Bpodname%3Dleo-0%2Bnamespace%3Dleo1839%2Bname%3Dleo%2Bimage%3Dulissigroup%252fkubeflow%253aarl/home/jovyan/shared-scratch/leo/alse/example/test_alse.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m algo\u001b[39m.\u001b[39minitialize_model([\u001b[39m\"\u001b[39m\u001b[39mreg\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mreg\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mreg\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell://k8s-container%2Bcontext%3Dulissigroup-desktops%2Bpodname%3Dleo-0%2Bnamespace%3Dleo1839%2Bname%3Dleo%2Bimage%3Dulissigroup%252fkubeflow%253aarl/home/jovyan/shared-scratch/leo/alse/example/test_alse.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m algo\u001b[39m.\u001b[39;49mnext_test_points(\u001b[39m5\u001b[39;49m)\n",
      "File \u001b[0;32m~/shared-scratch/leo/alse/alse/alse.py:73\u001b[0m, in \u001b[0;36malse.next_test_points\u001b[0;34m(self, num_points)\u001b[0m\n\u001b[1;32m     65\u001b[0m model_list \u001b[39m=\u001b[39m ModelListGP(\u001b[39m*\u001b[39m[model \u001b[39mfor\u001b[39;00m model \u001b[39min\u001b[39;00m list_of_models_temp])\n\u001b[1;32m     66\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meci \u001b[39m=\u001b[39m ExpectedCoverageImprovement(\n\u001b[1;32m     67\u001b[0m     model\u001b[39m=\u001b[39mmodel_list,\n\u001b[1;32m     68\u001b[0m     constraints\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_constraints,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m     num_samples\u001b[39m=\u001b[39m\u001b[39m512\u001b[39m,\n\u001b[1;32m     72\u001b[0m )\n\u001b[0;32m---> 73\u001b[0m x_next, _ \u001b[39m=\u001b[39m optimize_acqf(\n\u001b[1;32m     74\u001b[0m     acq_function\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meci,\n\u001b[1;32m     75\u001b[0m     bounds\u001b[39m=\u001b[39;49mnormalized_bounds,\n\u001b[1;32m     76\u001b[0m     q\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     77\u001b[0m     num_restarts\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[1;32m     78\u001b[0m     raw_samples\u001b[39m=\u001b[39;49m\u001b[39m512\u001b[39;49m,\n\u001b[1;32m     79\u001b[0m     \u001b[39m# fixed_features_list=[{2: 0, 2: 1, 3: 0.9}]\u001b[39;49;00m\n\u001b[1;32m     80\u001b[0m )\n\u001b[1;32m     81\u001b[0m list_of_models_temp \u001b[39m=\u001b[39m []\n\u001b[1;32m     82\u001b[0m train_x_temp \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((train_x_temp, x_next))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/botorch/optim/optimize.py:184\u001b[0m, in \u001b[0;36moptimize_acqf\u001b[0;34m(acq_function, bounds, q, num_restarts, raw_samples, options, inequality_constraints, equality_constraints, fixed_features, post_processing_func, batch_initial_conditions, return_best_only, sequential, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m batched_ics \u001b[39m=\u001b[39m batch_initial_conditions\u001b[39m.\u001b[39msplit(batch_limit)\n\u001b[1;32m    182\u001b[0m \u001b[39mfor\u001b[39;00m i, batched_ics_ \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(batched_ics):\n\u001b[1;32m    183\u001b[0m     \u001b[39m# optimize using random restart optimization\u001b[39;00m\n\u001b[0;32m--> 184\u001b[0m     batch_candidates_curr, batch_acq_values_curr \u001b[39m=\u001b[39m gen_candidates_scipy(\n\u001b[1;32m    185\u001b[0m         initial_conditions\u001b[39m=\u001b[39;49mbatched_ics_,\n\u001b[1;32m    186\u001b[0m         acquisition_function\u001b[39m=\u001b[39;49macq_function,\n\u001b[1;32m    187\u001b[0m         lower_bounds\u001b[39m=\u001b[39;49mbounds[\u001b[39m0\u001b[39;49m],\n\u001b[1;32m    188\u001b[0m         upper_bounds\u001b[39m=\u001b[39;49mbounds[\u001b[39m1\u001b[39;49m],\n\u001b[1;32m    189\u001b[0m         options\u001b[39m=\u001b[39;49m{\n\u001b[1;32m    190\u001b[0m             k: v\n\u001b[1;32m    191\u001b[0m             \u001b[39mfor\u001b[39;49;00m k, v \u001b[39min\u001b[39;49;00m options\u001b[39m.\u001b[39;49mitems()\n\u001b[1;32m    192\u001b[0m             \u001b[39mif\u001b[39;49;00m k \u001b[39mnot\u001b[39;49;00m \u001b[39min\u001b[39;49;00m (\u001b[39m\"\u001b[39;49m\u001b[39minit_batch_limit\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mbatch_limit\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mnonnegative\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    193\u001b[0m         },\n\u001b[1;32m    194\u001b[0m         inequality_constraints\u001b[39m=\u001b[39;49minequality_constraints,\n\u001b[1;32m    195\u001b[0m         equality_constraints\u001b[39m=\u001b[39;49mequality_constraints,\n\u001b[1;32m    196\u001b[0m         fixed_features\u001b[39m=\u001b[39;49mfixed_features,\n\u001b[1;32m    197\u001b[0m     )\n\u001b[1;32m    198\u001b[0m     batch_candidates_list\u001b[39m.\u001b[39mappend(batch_candidates_curr)\n\u001b[1;32m    199\u001b[0m     batch_acq_values_list\u001b[39m.\u001b[39mappend(batch_acq_values_curr)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/botorch/generation/gen.py:166\u001b[0m, in \u001b[0;36mgen_candidates_scipy\u001b[0;34m(initial_conditions, acquisition_function, lower_bounds, upper_bounds, inequality_constraints, equality_constraints, options, fixed_features)\u001b[0m\n\u001b[1;32m    163\u001b[0m     fval \u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[1;32m    164\u001b[0m     \u001b[39mreturn\u001b[39;00m fval, gradf\n\u001b[0;32m--> 166\u001b[0m res \u001b[39m=\u001b[39m minimize(\n\u001b[1;32m    167\u001b[0m     f,\n\u001b[1;32m    168\u001b[0m     x0,\n\u001b[1;32m    169\u001b[0m     method\u001b[39m=\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmethod\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mSLSQP\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39mif\u001b[39;49;00m constraints \u001b[39melse\u001b[39;49;00m \u001b[39m\"\u001b[39;49m\u001b[39mL-BFGS-B\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    170\u001b[0m     jac\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    171\u001b[0m     bounds\u001b[39m=\u001b[39;49mbounds,\n\u001b[1;32m    172\u001b[0m     constraints\u001b[39m=\u001b[39;49mconstraints,\n\u001b[1;32m    173\u001b[0m     callback\u001b[39m=\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcallback\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    174\u001b[0m     options\u001b[39m=\u001b[39;49m{k: v \u001b[39mfor\u001b[39;49;00m k, v \u001b[39min\u001b[39;49;00m options\u001b[39m.\u001b[39;49mitems() \u001b[39mif\u001b[39;49;00m k \u001b[39mnot\u001b[39;49;00m \u001b[39min\u001b[39;49;00m [\u001b[39m\"\u001b[39;49m\u001b[39mmethod\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcallback\u001b[39;49m\u001b[39m\"\u001b[39;49m]},\n\u001b[1;32m    175\u001b[0m )\n\u001b[1;32m    176\u001b[0m candidates \u001b[39m=\u001b[39m fix_features(\n\u001b[1;32m    177\u001b[0m     X\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfrom_numpy(res\u001b[39m.\u001b[39mx)\u001b[39m.\u001b[39mto(initial_conditions)\u001b[39m.\u001b[39mreshape(shapeX),\n\u001b[1;32m    178\u001b[0m     fixed_features\u001b[39m=\u001b[39mfixed_features,\n\u001b[1;32m    179\u001b[0m )\n\u001b[1;32m    181\u001b[0m clamped_candidates \u001b[39m=\u001b[39m columnwise_clamp(\n\u001b[1;32m    182\u001b[0m     X\u001b[39m=\u001b[39mcandidates, lower\u001b[39m=\u001b[39mlower_bounds, upper\u001b[39m=\u001b[39mupper_bounds, raise_on_violation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    183\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/scipy/optimize/_minimize.py:692\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    689\u001b[0m     res \u001b[39m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[1;32m    690\u001b[0m                              \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n\u001b[1;32m    691\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39ml-bfgs-b\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 692\u001b[0m     res \u001b[39m=\u001b[39m _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[1;32m    693\u001b[0m                            callback\u001b[39m=\u001b[39;49mcallback, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moptions)\n\u001b[1;32m    694\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtnc\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    695\u001b[0m     res \u001b[39m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[39m=\u001b[39mcallback,\n\u001b[1;32m    696\u001b[0m                         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/scipy/optimize/_lbfgsb_py.py:308\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    306\u001b[0m         iprint \u001b[39m=\u001b[39m disp\n\u001b[0;32m--> 308\u001b[0m sf \u001b[39m=\u001b[39m _prepare_scalar_function(fun, x0, jac\u001b[39m=\u001b[39;49mjac, args\u001b[39m=\u001b[39;49margs, epsilon\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    309\u001b[0m                               bounds\u001b[39m=\u001b[39;49mnew_bounds,\n\u001b[1;32m    310\u001b[0m                               finite_diff_rel_step\u001b[39m=\u001b[39;49mfinite_diff_rel_step)\n\u001b[1;32m    312\u001b[0m func_and_grad \u001b[39m=\u001b[39m sf\u001b[39m.\u001b[39mfun_and_grad\n\u001b[1;32m    314\u001b[0m fortran_int \u001b[39m=\u001b[39m _lbfgsb\u001b[39m.\u001b[39mtypes\u001b[39m.\u001b[39mintvar\u001b[39m.\u001b[39mdtype\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/scipy/optimize/_optimize.py:263\u001b[0m, in \u001b[0;36m_prepare_scalar_function\u001b[0;34m(fun, x0, jac, args, bounds, epsilon, finite_diff_rel_step, hess)\u001b[0m\n\u001b[1;32m    259\u001b[0m     bounds \u001b[39m=\u001b[39m (\u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39minf, np\u001b[39m.\u001b[39minf)\n\u001b[1;32m    261\u001b[0m \u001b[39m# ScalarFunction caches. Reuse of fun(x) during grad\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[39m# calculation reduces overall function evaluations.\u001b[39;00m\n\u001b[0;32m--> 263\u001b[0m sf \u001b[39m=\u001b[39m ScalarFunction(fun, x0, args, grad, hess,\n\u001b[1;32m    264\u001b[0m                     finite_diff_rel_step, bounds, epsilon\u001b[39m=\u001b[39;49mepsilon)\n\u001b[1;32m    266\u001b[0m \u001b[39mreturn\u001b[39;00m sf\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:158\u001b[0m, in \u001b[0;36mScalarFunction.__init__\u001b[0;34m(self, fun, x0, args, grad, hess, finite_diff_rel_step, finite_diff_bounds, epsilon)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf \u001b[39m=\u001b[39m fun_wrapped(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx)\n\u001b[1;32m    157\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_fun_impl \u001b[39m=\u001b[39m update_fun\n\u001b[0;32m--> 158\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_fun()\n\u001b[1;32m    160\u001b[0m \u001b[39m# Gradient evaluation\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \u001b[39mif\u001b[39;00m callable(grad):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:251\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update_fun\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    250\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf_updated:\n\u001b[0;32m--> 251\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_fun_impl()\n\u001b[1;32m    252\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf_updated \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:155\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdate_fun\u001b[39m():\n\u001b[0;32m--> 155\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf \u001b[39m=\u001b[39m fun_wrapped(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnfev \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    134\u001b[0m \u001b[39m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[39m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[39m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m fx \u001b[39m=\u001b[39m fun(np\u001b[39m.\u001b[39;49mcopy(x), \u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    138\u001b[0m \u001b[39m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39misscalar(fx):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/scipy/optimize/_optimize.py:76\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, x, \u001b[39m*\u001b[39margs):\n\u001b[1;32m     75\u001b[0m     \u001b[39m\"\"\" returns the the function value \"\"\"\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compute_if_needed(x, \u001b[39m*\u001b[39;49margs)\n\u001b[1;32m     77\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/scipy/optimize/_optimize.py:70\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39mall(x \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjac \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(x)\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m---> 70\u001b[0m     fg \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfun(x, \u001b[39m*\u001b[39;49margs)\n\u001b[1;32m     71\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjac \u001b[39m=\u001b[39m fg[\u001b[39m1\u001b[39m]\n\u001b[1;32m     72\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value \u001b[39m=\u001b[39m fg[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/botorch/generation/gen.py:152\u001b[0m, in \u001b[0;36mgen_candidates_scipy.<locals>.f\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    144\u001b[0m X \u001b[39m=\u001b[39m (\n\u001b[1;32m    145\u001b[0m     torch\u001b[39m.\u001b[39mfrom_numpy(x)\n\u001b[1;32m    146\u001b[0m     \u001b[39m.\u001b[39mto(initial_conditions)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[39m.\u001b[39mrequires_grad_(\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    150\u001b[0m )\n\u001b[1;32m    151\u001b[0m X_fix \u001b[39m=\u001b[39m fix_features(X, fixed_features\u001b[39m=\u001b[39mfixed_features)\n\u001b[0;32m--> 152\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39m-\u001b[39macquisition_function(X_fix)\u001b[39m.\u001b[39msum()\n\u001b[1;32m    153\u001b[0m \u001b[39m# compute gradient w.r.t. the inputs (does not accumulate in leaves)\u001b[39;00m\n\u001b[1;32m    154\u001b[0m gradf \u001b[39m=\u001b[39m _arrayify(torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mgrad(loss, X)[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mcontiguous()\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/botorch/utils/transforms.py:220\u001b[0m, in \u001b[0;36mt_batch_mode_transform.<locals>.decorator.<locals>.decorated\u001b[0;34m(acqf, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[39m# add t-batch dim\u001b[39;00m\n\u001b[1;32m    219\u001b[0m X \u001b[39m=\u001b[39m X \u001b[39mif\u001b[39;00m X\u001b[39m.\u001b[39mdim() \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m \u001b[39melse\u001b[39;00m X\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\n\u001b[0;32m--> 220\u001b[0m output \u001b[39m=\u001b[39m method(acqf, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    221\u001b[0m \u001b[39mif\u001b[39;00m assert_output_shape \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m _verify_output_shape(\n\u001b[1;32m    222\u001b[0m     acqf\u001b[39m=\u001b[39macqf,\n\u001b[1;32m    223\u001b[0m     X\u001b[39m=\u001b[39mX,\n\u001b[1;32m    224\u001b[0m     output\u001b[39m=\u001b[39moutput,\n\u001b[1;32m    225\u001b[0m ):\n\u001b[1;32m    226\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[1;32m    227\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mExpected the output shape to match either the t-batch shape of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    228\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mX, or the `model.batch_shape` in the case of acquisition functions\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    229\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39musing batch models; but got output with shape \u001b[39m\u001b[39m{\u001b[39;00moutput\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    230\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfor X with shape \u001b[39m\u001b[39m{\u001b[39;00mX\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    231\u001b[0m     )\n",
      "File \u001b[0;32m~/shared-scratch/leo/alse/alse/eci.py:120\u001b[0m, in \u001b[0;36mExpectedCoverageImprovement.forward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    116\u001b[0m domain_mask \u001b[39m=\u001b[39m smooth_mask(\n\u001b[1;32m    117\u001b[0m     ball_around_X, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbounds[\u001b[39m0\u001b[39m, :], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbounds[\u001b[39m1\u001b[39m, :]\n\u001b[1;32m    118\u001b[0m )\u001b[39m.\u001b[39mprod(dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    119\u001b[0m num_points_in_integral \u001b[39m=\u001b[39m domain_mask\u001b[39m.\u001b[39msum(dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m--> 120\u001b[0m base_point_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_base_point_mask(ball_around_X)\u001b[39m.\u001b[39mprod(dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    121\u001b[0m prob \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_estimate_probabilities_of_satisfaction_at_points(ball_around_X)\n\u001b[1;32m    122\u001b[0m masked_prob \u001b[39m=\u001b[39m prob \u001b[39m*\u001b[39m domain_mask \u001b[39m*\u001b[39m base_point_mask\n",
      "File \u001b[0;32m~/shared-scratch/leo/alse/alse/eci.py:78\u001b[0m, in \u001b[0;36mExpectedCoverageImprovement._get_base_point_mask\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_base_point_mask\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m---> 78\u001b[0m     distance_matrix \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mmodels[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mcovar_module\u001b[39m.\u001b[39;49mbase_kernel\u001b[39m.\u001b[39;49mcovar_dist(\n\u001b[1;32m     79\u001b[0m         X\u001b[39m.\u001b[39;49mfloat(), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbase_points\u001b[39m.\u001b[39;49mfloat()\n\u001b[1;32m     80\u001b[0m     )\n\u001b[1;32m     81\u001b[0m     \u001b[39mreturn\u001b[39;00m smooth_mask(distance_matrix, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpunchout_radius)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/gpytorch/kernels/kernel.py:329\u001b[0m, in \u001b[0;36mKernel.covar_dist\u001b[0;34m(self, x1, x2, diag, last_dim_is_batch, square_dist, dist_postprocess_func, postprocess, **params)\u001b[0m\n\u001b[1;32m    327\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistance_module\u001b[39m.\u001b[39m_sq_dist(x1, x2, postprocess, x1_eq_x2)\n\u001b[1;32m    328\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 329\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdistance_module\u001b[39m.\u001b[39;49m_dist(x1, x2, postprocess, x1_eq_x2)\n\u001b[1;32m    331\u001b[0m \u001b[39mreturn\u001b[39;00m res\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/gpytorch/kernels/kernel.py:54\u001b[0m, in \u001b[0;36mDistance._dist\u001b[0;34m(self, x1, x2, postprocess, x1_eq_x2)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_dist\u001b[39m(\u001b[39mself\u001b[39m, x1, x2, postprocess, x1_eq_x2\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m     53\u001b[0m     \u001b[39m# TODO: use torch cdist once implementation is improved: https://github.com/pytorch/pytorch/pull/25799\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sq_dist(x1, x2, postprocess\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, x1_eq_x2\u001b[39m=\u001b[39;49mx1_eq_x2)\n\u001b[1;32m     55\u001b[0m     res \u001b[39m=\u001b[39m res\u001b[39m.\u001b[39mclamp_min_(\u001b[39m1e-30\u001b[39m)\u001b[39m.\u001b[39msqrt_()\n\u001b[1;32m     56\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_postprocess(res) \u001b[39mif\u001b[39;00m postprocess \u001b[39melse\u001b[39;00m res\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/gpytorch/kernels/kernel.py:31\u001b[0m, in \u001b[0;36mDistance._sq_dist\u001b[0;34m(self, x1, x2, postprocess, x1_eq_x2)\u001b[0m\n\u001b[1;32m     29\u001b[0m adjustment \u001b[39m=\u001b[39m x1\u001b[39m.\u001b[39mmean(\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m, keepdim\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     30\u001b[0m x1 \u001b[39m=\u001b[39m x1 \u001b[39m-\u001b[39m adjustment\n\u001b[0;32m---> 31\u001b[0m x2 \u001b[39m=\u001b[39m x2 \u001b[39m-\u001b[39;49m adjustment  \u001b[39m# x1 and x2 should be identical in all dims except -2 at this point\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[39m# Compute squared distance matrix using quadratic expansion\u001b[39;00m\n\u001b[1;32m     34\u001b[0m x1_norm \u001b[39m=\u001b[39m x1\u001b[39m.\u001b[39mpow(\u001b[39m2\u001b[39m)\u001b[39m.\u001b[39msum(dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, keepdim\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (512) must match the size of tensor b (10) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.quasirandom import SobolEngine\n",
    "\n",
    "import numpy as np\n",
    "from alse.accuracy import get_accuracy\n",
    "from alse.utils import identify_samples_which_satisfy_constraints, normalize, unnormalize\n",
    "from mpl_toolkits import mplot3d\n",
    "# from matplotlib import cm\n",
    "from alse.utils import read_excel\n",
    "from alse.alse import alse\n",
    "import copy\n",
    "tkwargs = {\n",
    "    \"device\": torch.device(\"cpu\"),\n",
    "    \"dtype\": torch.float,\n",
    "}\n",
    "\n",
    "X, width, pow_cap, wth = read_excel(\"../test_data/trial_NaN.xlsx\",[\"P (W)\", \"V (mm/min)\"], [\"widths avg (mm)\", \"powder capt %\", \"wth\"])\n",
    "bounds = torch.tensor([[900, 600], [2700, 1800]])\n",
    "constraints = [(\"gt\", 2.5), (\"gt\", 0.65), (\"gt\", 6)]\n",
    "\n",
    "algo = alse(X, bounds, [width, pow_cap, wth], constraints)\n",
    "\n",
    "algo.initialize_model([\"reg\", \"reg\", \"reg\"])\n",
    "\n",
    "algo.next_test_points(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f18aec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo.get_acq_val_grid()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
