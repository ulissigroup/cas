{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "from botorch.models import ModelListGP, SingleTaskGP\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from gpytorch.models import ExactGP\n",
    "from gpytorch.likelihoods import DirichletClassificationLikelihood\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.kernels import ScaleKernel, RBFKernel\n",
    "import torch\n",
    "from botorch.acquisition.monte_carlo import MCAcquisitionFunction\n",
    "from botorch.acquisition.objective import IdentityMCObjective\n",
    "from botorch.fit import fit_gpytorch_model\n",
    "from botorch.models import ModelListGP, SingleTaskGP\n",
    "from botorch.models.transforms.outcome import Standardize\n",
    "from botorch.optim import optimize_acqf\n",
    "from botorch.utils.sampling import sample_hypersphere\n",
    "from botorch.utils.transforms import t_batch_mode_transform\n",
    "from gpytorch.constraints import Interval\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from torch.quasirandom import SobolEngine\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import random\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRand(r1, r2, num):\n",
    "    return (r1 - r2) * torch.rand(num, 1) + r2\n",
    "    \n",
    "def gen_data(num_data):\n",
    "    x = getRand(-3, 3, num_data)\n",
    "    y = getRand(-3, 3, num_data)\n",
    "    \n",
    "    data_fn = lambda x, y: torch.sin(0.15 * 3.1415 * (x + y)) + 1\n",
    "    '''↓ Uncomment to test a more complicated function ↓'''\n",
    "    # data_fn = lambda x, y: (x**2+y-11)**2+(x+y**2-7)**2\n",
    "\n",
    "    latent_fn = data_fn(x, y)\n",
    "    z = latent_fn.long()  \n",
    "    ''' .long() will convert z to integers \n",
    "        (Do not squeeze, SingleTask GP requires 2xD) '''\n",
    "    return torch.cat((x,y),dim=1), z, data_fn\n",
    "\n",
    "train_x, train_y, genfn = gen_data(20) # 20 points\n",
    "plt.scatter(train_x[:,0].numpy(), train_x[:,1].numpy(), c = train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test data set (Not implemented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_known_data():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Change this varibale to change reshape tensor size '''\n",
    "res = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference: actual boundry plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_d1 = np.linspace(-3, 3, res)\n",
    "test_d2 = np.linspace(-3, 3, res)\n",
    "test_x_mat, test_y_mat = np.meshgrid(test_d1, test_d2)\n",
    "test_x_mat, test_y_mat = torch.Tensor(test_x_mat), torch.Tensor(test_y_mat)\n",
    "test_x = torch.cat((test_x_mat.view(-1,1), test_y_mat.view(-1,1)),dim=1)\n",
    "test_labels = genfn(test_x_mat, test_y_mat).long().squeeze() \n",
    "''' ↑ Use .long() to Convert to integers (0 or 1) ↑ '''\n",
    "test_y = test_labels.view(-1)\n",
    "plt.contourf(test_x_mat.numpy(), test_y_mat.numpy(), test_labels.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare model for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "octf = Standardize(m=train_y.shape[-1])\n",
    "train_x = torch.tensor(train_x, dtype=torch.float64) \n",
    "train_y = torch.tensor(train_y, dtype=torch.float64)\n",
    "''' ↑ Set dtype to compatible type ↑ '''\n",
    "likelihood = GaussianLikelihood(noise_constraint=Interval(1e-6, 1e-3))\n",
    "model = SingleTaskGP(train_x, train_y, likelihood=likelihood, outcome_transform=octf)\n",
    "mll = ExactMarginalLogLikelihood(model.likelihood, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_gpytorch_model(mll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "I don't think it's necessary to put model in eval mode \n",
    "↓ But I've left it on in case something subtle is happening ↓\n",
    "'''\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "with gpytorch.settings.fast_pred_var(), torch.no_grad():\n",
    "    test_dist = model(test_x.double())\n",
    "    pred_means = test_dist.loc\n",
    "\n",
    "# print(test_x.shape)\n",
    "# print(test_dist)\n",
    "# print(pred_means.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logit plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize = (8, 6))\n",
    "im = ax.contourf(\n",
    "    test_x_mat.numpy(), test_y_mat.numpy(), pred_means.numpy().reshape((res, res))\n",
    ")\n",
    "fig.colorbar(im, ax=ax)\n",
    "ax.set_title(\"Logits: Class \" + str(0), fontsize = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approximate probability with a lightweight sampling step using J samples from the posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_samples = test_dist.sample(torch.Size((256,1))).exp()\n",
    "probabilities = (pred_samples / pred_samples.sum(-1, keepdim=True)).mean(0)*100\n",
    "''' Don't know why I need x100 '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probability plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize = (7, 6))\n",
    "levels = np.linspace(0, 1.05, 50)\n",
    "\n",
    "im = ax.contourf(\n",
    "    test_x_mat.numpy(), test_y_mat.numpy(), probabilities.numpy().reshape((res, res)), levels=levels\n",
    ")\n",
    "fig.colorbar(im, ax=ax)\n",
    "ax.set_title(\"Probabilities: Class \" + str(0), fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_means = torch.unsqueeze(pred_means, 0) \n",
    "''' ↑ Unsqueeze pred_means to plot the boundries ↑ '''\n",
    "fig, ax = plt.subplots(1,2, figsize=(10, 5))\n",
    "\n",
    "ax[0].contourf(test_x_mat.numpy(), test_y_mat.numpy(), test_labels.numpy())\n",
    "ax[0].set_title('True Response', fontsize=20)\n",
    "ax[1].contourf(test_x_mat.numpy(), test_y_mat.numpy(), pred_means.max(0)[0].reshape((res, res)))\n",
    "ax[1].set_title('Estimated Response', fontsize=20)\n",
    "\n",
    "'''\n",
    "In the future we should probably use something other than contour plot\n",
    "As this classification model only predicts the boundries (if I am understanding this correctly)\n",
    "But I don't know hot to plot the predicted boundry\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1fa163922eb0b3709bbb5d8082b2465c9de796dbaacca80cbaa600e7fff3e4fe"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
